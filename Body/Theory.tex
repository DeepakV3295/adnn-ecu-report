\part{Introduction}

\textit{Neural network training and inference in embedded environments}

{\color{red}
	Talk about the number of devices in the space of embedded systems / tiny devices (Estimates put the total number of these devices north of 20 billion) and about the potential of running machine learning on that compute. Introduce sustainability notion of utilising those embedded devices for the purpose of performing ML computes as a means of efficient utilisation ... However  much of the potential of running machine learning appilations on them remain unattained due to the difficulties in creating these applications

	Among the approaches that would be salient on these platforms, neural network approaches are the most sought after owing to the unprecedented progress made in their practical applications. Tiny Machine Learning is a burgeoning field that looks at how this space of embedded devices can be made more suitable to create and explore the potential machine learning applications that it can support. An important feature of machine learning applications are their iterative improvement process. For neural network applications this happens during the training process which traditionally consumes a lot of compute resource

}

\subsubsection{Why perform training and inference on ECUs?}

In the world of embedded systems resources such as compute, memory, network bandwith etc. are all limited. The traditional model of sending data from embedded device sensors off-board to compute clusters on the cloud presents several challenges such as bandwith consumption, privacy considerations, and more that makes it attractive to perform both training and inference on-board the embedded device

{\color{red}
	\textit{Federated Learning}
One approach to making this training loop take place from within these platforms is Federated Learning which cruicially allows for the data to remain on the device
}

\chapter{Background}
\textit{Describe ECU systems, Tiny ML}

\vspace{1em}
\noindent \textbf{Hypothesis}: Training and inference of (small) neural networks in embedded systems can be considerably improved compared to general purpose neural networks frameworks

\section{Anomally Detection}
\textit{Explain the problem. Introduce terminlogy that will get explained in the next chapter}

\subsection{Considerations in Embedded Environments}

\section{Scania Embedded Systems}
\textit{ECU systems, the kind of data they generate, and the potential applications}

\subsection{i.MX6 Target Processor}
\textit{i.MX6 specifications and constraints}

\section{Development for Embedded Linux}
\textit{Short introduction to writing applications for embedded linux}

\subsection{Yocto Project}
\textit{Outline the Yocto Project based Build environment}

\chapter{Theory}
\textit{Theoretical foundations}

\section{Expectations for the Hardware}
\textit{Layout the Architecture of the i.MX6 - ISA and specifications. Optimisation possibilities through using the SIMD etc}

\subsection{Training vs Inference}
\textit{Requirements for Training and uploading the wieghts vs Inference}

\section{Neural Network Performance Optimisations Techniques}
\textit{Contrast traditional implementations in resource rich environments and the constraints of embedded environment. Layout general strategies to acquire performance improvements with little losses to accuracy e.g Purning, Quantisation}

\section{Tiny Machine Learning}
\textit{Approaches to doing Machine Learning in Embedded Environments}

\section{ARM's CMSIS-NN}
\textit{Introduction to ARM CMSIS-NN Kernels}
