\part{Implementation}

The traditional model for deploying neural network applications on embedded devices has over time developed the neural network inference step. The popular frameworks for machine learning such as PyTorch and Tensorflow provide approaches for porting neural network models written using those frameworks with a focus on allowing for model inference on embedded platforms. Under this paradigm, training would be completed on more powerful hardware and the data would have to be collected seperately to allow for the continual training of the neural network model. Targetting even smaller devices with Tensorflow based neural network models is possible for neural network inference applications via Tensorflow Lite Micro \cite{tflm} further expanding the range of platforms that this paradigm applies. Efforts to allow training as well in these frameworks require more effort due to the compute and memory intensive nature of the training process. Another reason for the delay in adopting training on board is fragmented nature of embedded ecosystem and the difficulties involved in streamlining features for any machine learning framework that would have to support the varied hardware platforms in the ecosystem.

This part of the report contains the description of multiple application programs that train a neural network model for the purpose of benchmarking the training step on an embedded device. The neural network structure, the learning algorithm, and the dataset remain the same across the implementations however they are completed in a traditional general purpose neural network frameworks as well as straightforward implementations in \texttt{C}, \texttt{C++}, and Python. The design of the neural network is based on a textbook example and is kept configurable to allow for testing across different neural network architectures. Greater detail on the design is presented in the first chapter, followed by another chapter describing the different implementations.

% ============================================
%        Design
% ============================================

\chapter{Design}

The benchmark applications test the training of a Handwritten Digit Recognition Neural Network (HDR-NN) on the MNIST \cite{mnist} dataset. MNIST is a popular dataset of handwritten digits commonly used for training image processing systems. It is a popular starting point for neural network implementations and has been used as the primary dataset for the benchmark experiments.

\section[Handwritten Digit Recognition (HDR)]{HDR-NN Benchmark Programs}

The handwritten digit recognition neural network is a fully connected neural network and derives from the popular neural network textbook \href{http://neuralnetworksanddeeplearning.com}{neuralnetworksanddeeplearning.com}

The input layer has 784 neurons corresponding to 28 x 28 pixel images of the MNIST dataset and the output layer has 10 neurons corresponds to 10 different possible digits. The dimensions and depth of hidden layers of the network is configurable as well as other properties of the learning algorithm. The network uses the sigmoid activation function and uses a 32 bit floating point representation for its weights and biases.

\begin{center}
	\begin{tikzpicture}[x=2.4cm, y=1cm]
		\readlist\Shape{4,3,2,2}
		\readlist\Type{1,2,2,3}
		\readlist\Label{x,h^{(\prev)},h^{(\prev)},y}

		\def\yshift{0.5} % shift last node for dots

		\foreachitem \N \in \Shape{ % loop over layers
			\def\lay{\Ncnt} % alias of index of current layer
			\pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
			\message{\lay,}
			\foreach \i [evaluate={
				\c=int(\i==\N);
				\y=\N/2-\i-\c*\yshift;
				\x=\lay; \n=\Type[\lay];
				}] in {1,...,\N}{
			\node[node \n] (N\lay-\i) at (\x,\y) {$\Label[\lay]$};

			\ifnum\lay>1
				\foreach \j in {1,...,\Shape[\prev]}{
				\draw[connect,white,line width=1.2] (N\prev-\j) -- (N\lay-\i);
				\draw[connect] (N\prev-\j) -- (N\lay-\i);
				}
			\fi
			}
			\path (N\lay-\N) --++ (0,1+\yshift) node[midway,scale=1.5] {$\vdots$};
		}
	\end{tikzpicture}
	\qquad
	\begin{tikzpicture}[x=2cm,y=1cm]
		\readlist\Shape{4,7,2}
		\readlist\Type{1,2,3}
		\readlist\Label{x,h^{(\prev)},y}

		\def\yshift{0.45}

		\foreachitem \N \in \Shape{
			\def\lay{\Ncnt}
			\pgfmathsetmacro\prev{int(\Ncnt-1)}

			\foreach \i [evaluate={
				\c=int(\i==\N);
				\y=\N/2-\i-\c*\yshift;
				\x=\lay; \n=\Type[\lay];
				}] in {1,...,\N}{

			\node[node \n] (N\lay-\i) at (\x,\y) {$\Label[\lay]$};

			\ifnum\lay>1
				\foreach \j in {1,...,\Shape[\prev]}{
				\draw[connect,white,line width=1.2] (N\prev-\j) -- (N\lay-\i);
				\draw[connect] (N\prev-\j) -- (N\lay-\i);
				}
			\fi
			}

			\path (N\lay-\N) --++ (0,1+\yshift) node[midway,scale=1.5] {$\vdots$};
		}
	\end{tikzpicture}
\end{center}

The benchmark programs would also compute charactersitics of the neural network such as accuracy and are also capable of producing a dump of the network values such as the hidden layer structure, weight and bias values, etc. into a \texttt{.nn} binary file format. The \texttt{.nn} binary format can then be consumed by any of the implementations to perform an image inference. For instance, the \texttt{C} based benchmark application could produce a \texttt{.nn} file after training the network and then the Python based benchmark application can then take that file as input to complete a feedforward pass for an MNIST 28 x 28 image in PGM format. The feedforward pass between different implementations of the benchmark applications can be compared in this manner as well.

\subsection{The Learning Algorithm}

The HDR-NN benchmark applications all share the same standard training algorithm listed below (\ref{alg:cap}). Describing this algorithm in general purpose neural network frameworks is straight forward and plenty of general implementations of the algorithm exists, making the development process easier to target multiple programming paradigms. The configurable parameters of the learning algorithm through out the implementations are the learning rate, the total number of epochs for training, and the batch size for gradient descent iterations.

\begin{algorithm}[h]
	\caption{Mini Batch Gradient Descent with learning rate $\gamma$ and the Mean Squared Error (\texttt{MSE}) cost function}
	\label{alg:cap}
	\begin{algorithmic}
	\Require initial weights $w^{(0)}$, number of epochs $E$, batch size $B$, training data with $T$ entries
	\Ensure final weights $w^{(E*T)}$
	\For{$e = 0 \rightarrow E - 1$}
		\For{$b = 0 \rightarrow T / B$}
			\For{$t = b * B \rightarrow (b+1) * B$}
			\State estimate $\nabla \mathcal{L}(w^{(t)})$ \Comment{$\mathcal{L}$ here is \texttt{MSE}}
			\State compute $\Delta w^{(b)} += - \nabla \mathcal{L}(w^{(t)})$\label{lin:deep-learning-delta-w}
			\EndFor
			\State $w^{(e + 1)} := w^{(e)} + \gamma \Delta w^{(e)}$
		\EndFor
	\EndFor
	\State return $w^{(T)}$
	\end{algorithmic}
\end{algorithm}

% TODO : Add a good description for the mini batch gradient descent algorithm that is used here

\subsection{Training Configurations}

The model structure can be configured in the same manner across the implementations, as well as the learning algorithm configuration. This means that the shape of the model, the input parameters, the connections between the neuron can be configured in the same manner across the implementations. Furthermore, the learning rate, the number of epochs, and the batch size are also configurable in the same manner.

\subsubsection{UX for configuring learning algorithm parameters and other configurations}
\label{section:hdrnn-ux}

All benchmark applications upon invocation without any arguments presents a helpful usage string

\begin{lstlisting}[language=Bash]
	./hdrnn

	nothing to perform
	Usage: ./hdrnn <command> [<args>]

	Commands:
		infer [-i, --image IMAGE_PATH] [-n, --net hdr.nn]
		train [-s, --shape 32] [-e, --epochs 30]
				[-q, --quiet] [-bs, --batch_size=10]
				[-lr, --learning_rate 3.0] [-n, --net hdr.nn]
\end{lstlisting}

Running a training pass of the network can be as simple as

\begin{lstlisting}[language=Bash]
	./hdr train
\end{lstlisting}

This execution will run for 30 epochs with a learning rate of 3.0 and batch size of 10 on a neural network with shape [784, 32, 10]. After the training completes, the program will then output a network description file \texttt{hdr.nn} with the shape, weights and biases of the network. This file can then be later used to perform an inference only run by running the following command.

\begin{lstlisting}[language=Bash]
	./hdr infer --image 7.pgm --net hdr.nn
\end{lstlisting}

The \texttt{C} version of the benchmark application can also produce sketch of the image on to stdout, the shell for example, along with the prediction that the network makes and would produce the following output

\begin{lstlisting}[language=Bash]



						x x x x x
						x x x x x
					x x x x x x
					x x x x x x x x x
					x x x x x x x x x x
				x x x x x x x x x x x
				x x x x x x x x x x x x x
			x x x x x x x x     x x x x x x
			x x x x x x           x x x x x
			x x x x x             x x x x x
			x x x                 x x x x x
			x x x                 x x x x x
			x x x             x x x x x x x
			x x x             x x x x x x
			x x x           x x x x x x
			x x x x x x x x x x x x x
			x x x x x x x x x x x x x
			x x x x x x x x x x x x x
				x x x x x x x x x
					x x x x x x x




Network predicts 0
\end{lstlisting}

\begin{figure}[h]
	\centering
	\includegraphics[scale=1]{3.jpg}
\end{figure}

To change the network shape and epoch parameters, for example, run:

\begin{lstlisting}[language=Bash]
	./hdr train --shape 16,16 --epoch 4 -q
\end{lstlisting}

The program will then train a new network of shape [784, 16, 16, 10] for 4 epochs and silently exit without producing the \texttt{hdr.nn} file as the -q quiet flag was present. The complete list of program parameters are given below.

\textbf{Silent invocation}

Use silent invocation using the \texttt{--quiet} or \texttt{-q} flag

When used with the `train` command, the final weights and biases files won't be generated

\begin{lstlisting}[language=Bash]
	./hdr train --quiet
\end{lstlisting}

\textbf{Epochs}

The number of epochs to train the network, specified by \texttt{--epochs} or \texttt{-e} followed by a natural number

\begin{lstlisting}[language=Bash]
	./hdr train --epochs 21
\end{lstlisting}

\textbf{Network Shape}

The size and shape of the HDR-NN network as comma seperated numbers after the \texttt{--shape} or \texttt{-s} flag

\begin{lstlisting}[language=Bash]
	./hdr train --shape 16,16
\end{lstlisting}

\textbf{Learning Rate}

The learning rate for the Stochastic Gradient Descent as a floating point value after the \texttt{-lr} or \texttt{--learning\_rate} flag

\begin{lstlisting}[language=Bash]
	./hdr train --learning_rate 3.1
\end{lstlisting}

\textbf{Batch Size}

The batch size while performing mSGD as an integer after the \texttt{--batch\_size} or \texttt{-bs} flag

\begin{lstlisting}[language=Bash]
	./hdr train --batch_size 64
\end{lstlisting}


% ============================================
%        Development
% ============================================

\chapter{Development}

The HDR-NN benchmark applications were completed in different programming languages and in PyTorch. Details about the target environment and the benchmark implementations are layed out in this chapter

\section{Targeting MCIMX6Q-SDB}

The target environment necessitates the use of cross compilers and as part of the development process multiple build environments and systems were examined. Ultimately, the primary platform that ended up being used was the Yocto Project extensible SDK (eSDK) based application development process running on a standard linux based build environment. The QEMU emulator was also employed at various staged to check the build, and further test the application before moving onto tests on the actual hardware.

\subsection{Compiler Toolchains \& Yocto Recipes}

The \textit{meta-freescale} Yocto BSP layer by NXP supports the target processor and in combination with the Poky reference distribution provides an eSDK that was primarily used to test and develop the benchmark applications.

GCC based cross compilers and debuggers were usefull for the \texttt{C}, \texttt{C++}  programs. The \textit{meta-python} layer provided by Open Embedded was also useful in allowing for applications using Python and Numpy. The general portability of the benchmark applications and the Yocto project allows for further experiments to be conducted on different target architectures as well.

\subsection{Building PyTorch for armv7hl}

PyTorch project provides LibTorch as a binary distribution of all the headers, libraries, CMake configurations required to use PyTorch. However the PyTorch project does not provide these binaries for MCIMX6Q-SDB. The source code could however, with some effort, be used to generate these binaries and for this project a QEMU based user-mode emulation environment was used for native compilation of the libtorch binaries.

\subsection{i.MX6 Overview}

The iMX6 series is designed for high performance low power applications and target boards are configured with a single Cortex A9 core with the ARMv7 ISA. The processor supports NEON single-instruction multiple-data (SIMD) instructions, allowing for SIMD vector operations within the training program

\section{HDR-NN Implementations}

With the primary focus on training, MNIST dataset was primarily loaded in an easily readable format appropriate to the corresponding paradigms and the correctness verification routines and execution statistics measurement runs were seperated. The benchmark executions did not produce disk I/O after the dataset was read, unlike the correctness verification runs which produced the final weights from the execution runs that were subsequently compared with the other benchmark program execution output weights

% TODO : Fill in greater detail on the different implementations

\subsection{The Reference HDR-NN in Python}

This is the baseline implementation and follows close to the implementation exhibitied on \href{http://neuralnetworksanddeeplearning.com}{neuralnetworksanddeeplearning.com}. The implementation uses the n-dimensional array data structure present in the popular Python programming language library Numpy. The following listing shows the function that performs feedforward pass in the Network.

\begin{lstlisting}[language=Python]
	class Network(object):

	def __init__(self, sizes):
		"""Initialise neural network"""
		self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
		self.weights = [np.random.randn(y, x)
		for x, y in zip(sizes[:-1], sizes[1:])]

	def feedforward(self, a):
		for b, w in zip(self.biases, self.weights):
			a = sigmoid(np.dot(w, a)+b)
		return a
\end{lstlisting}

% \subsection[Tensorflow Lite]{Tensorflow Lite based HDR-NN}

% Developing ANNs on tensorflow using Keras is straightforward with good support and well documented APIs. Building the same model for a Tensorflow Lite (TFLite) was more involved however still straightforward

\subsection{PyTorch based HDR-NN}

Developing ANNs using PyTorch is straightforward with good support and well documented APIs. There were two primary choices for programming language to write the neural network in PyTorch, namely Python and C++. PyTorch project does not provide binaries for either language choice for \texttt{armv7hl} however with the source code of the project being available, the libtorch binaries were generated as mention in the previous section.

The implementation used the MNIST made available by Torchvision library which is mainted under the PyTorch project and configured a Module to implement the same learning algorithm as that outlined in the Numpy based Python implementation.

\begin{lstlisting}[language=C++]
struct Net : torch::nn::Module
{
	Net(std::vector<unsigned int> shape)
	{
		// size of image in row vector form
		unsigned int previous_dim = IMAGE_SIZE;
		unsigned int index = 1;
		torch::nn::Linear fc{nullptr};

		// iterate over the dimensions required in the hidden layer
		for (auto c_dim : shape)
		{
			// Construct and register Linear submodules.
			fc = register_module(
				"fc" + std::to_string(index),
				torch::nn::Linear(previous_dim, c_dim));
			previous_dim = c_dim;
			index++;
			fc_list.push_back(fc);
		}

		// finally, add the last layer
		fc = register_module(
			"fc" + std::to_string(index),
			torch::nn::Linear(previous_dim, DIGITS));
		fc_list.push_back(fc);
	}

	// Implement the Net's algorithm.
	torch::Tensor forward(torch::Tensor x)
	{
		// Use one of many tensor manipulation functions.
		x = x.reshape({x.size(0), 784});
		for (auto fc : fc_list)
			x = torch::sigmoid(fc->forward(x));

		return x;
	}

	// Use one of many "standard library" modules.
	std::vector<torch::nn::Linear> fc_list{};
};
\end{lstlisting}


\subsection{C based HDR-NN}

The \texttt{C} implementation had the least amount of external dependencies, other than the \texttt{C} standard library. The data structures of the neural network contain float arrays within structs as shown in the listing below. The learning algorithm was implemented to remain identical with those used in the other implementations.

\begin{lstlisting}[language=C]
/* HDR Neural Network */
typedef struct
{
	float bias;
	float *weights;
	float *nabla_w;
} Neuron;

typedef struct LayerT
{
	int size;
	int incidents;
	Neuron *neurons;
	float *activations;
	float *z_values;
	float *nabla_b;
	struct LayerT *next;
	struct LayerT *previous;
} Layer; // Network layers except for input

typedef struct
{
	Layer *layers;
	int depth;
} Network; // HDRNN
\end{lstlisting}

\subsection{C++ based HDR-NN}

The \texttt{C++} implementation used the n-dimensional arrays of popular \texttt{C++} linear algebra library, Eigen. It is a straight forward port of the same structure and learning algorithm as the Numpy based Python implementation. A portion of the learning algorithm is shown in the listing below.

Compared to the \texttt{C} version, the \texttt{C++} version uses the richer language feature set of \texttt{C++} such as namespaces, classes, etc. The \texttt{C++} implementation uses the popular build automation tool \texttt{CMake} instead of the GNU autotools setup adopted by the \texttt{C} implementation.

\begin{lstlisting}[language=C++]
void mini_batch_sgd()
{
	// Initialize Nabla matrixes
	std::vector<nabla> nablas;
	for (std::size_t i = 0; i < network.size(); i++)
		nablas.push_back(
					nabla(network[i].weights.rows(),
						network[i].weights.cols())
					);

	// Go through the training data by batches
	for (std::size_t i = 0; i < mnist_loader::train.size()
				; i += BATCH_SIZE)
	{
		// Perform Backpropagation on the batch
		for (std::size_t j = 0; j < BATCH_SIZE; j++)
			back_propogate(nablas,
						mnist_loader::train[i+j].data,
						mnist_loader::train[i+j].label);

		// Update the weights and biases of the network
		for (std::size_t j = 0; j < network.size(); j++)
			network[j].update(nablas[j]);

		// Zero out the nabla matrixes
		for (std::size_t j = 0; j < nablas.size(); j++)
			nablas[j].zero_out();
	}
}
\end{lstlisting}