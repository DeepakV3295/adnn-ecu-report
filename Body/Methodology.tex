\part{Implementation}

The traditional model for deploying neural network applications on embedded devices has over time developed the neural network inference step. The popular frameworks for machine learning such as PyTorch and Tensorflow provide approaches for porting neural network models written using those frameworks with a focus on allowing for model inference. Targetting even smaller devices with Tensorflow based neural network models is possible for inference only applications via Tensorflow Lite Micro \cite{tflm}. Efforts to allow training as well in these frameworks require more effort due to the compute and memory intensive nature of the training process.

This section contains the description of applications that train a neural network model to benchmark the training step on an embedded device. The neural network structure, the learning algorithm, and the dataset remain the same but the implementations are completed in traditional general purpose neural network frameworks as well as straightforward implementations in \texttt{C}, \texttt{C++}, and Python. The design and development of these application and an overview of the target hardware to perform the benchmarking are covered in the following chapters.

% ============================================
%        Design
% ============================================

\chapter{Design}

The benchmark applications test the training phase of a Handwritten Digit Recognition Neural Network (HDR-NN) on the MNIST \cite{mnist} dataset. MNIST is a popular dataset of handwritten digits commonly used for training image processing systems. It is a popular starting point for neural network implementations and has been used as the primary dataset in the benchmark experiments. The target embedded device is an Electronic Control Unit (ECU) with a Cortex-A9 processor.

\section[Handwritten Digit Recognition (HDR)]{HDR-NN Benchmark Programs}

The handwritten digit recognition neural network is a fully connected neural network and derives from the popular neural network textbook \href{http://neuralnetworksanddeeplearning.com}{neuralnetworksanddeeplearning.com}

The input layer has 784 neurons corresponding to 28 x 28 pixel images of the MNIST dataset and the output layer has 10 neurons corresponds to 10 different possible digits. The dimensions and depth of hidden layers of the network is configurable as well as other properties of the learning algorithm

\begin{center}
	\begin{tikzpicture}[x=2.4cm, y=1cm]
		\readlist\Shape{4,3,2,2}
		\readlist\Type{1,2,2,3}
		\readlist\Label{x,h^{(\prev)},h^{(\prev)},y}

		\def\yshift{0.5} % shift last node for dots

		\foreachitem \N \in \Shape{ % loop over layers
			\def\lay{\Ncnt} % alias of index of current layer
			\pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
			\message{\lay,}
			\foreach \i [evaluate={
				\c=int(\i==\N);
				\y=\N/2-\i-\c*\yshift;
				\x=\lay; \n=\Type[\lay];
				}] in {1,...,\N}{
			\node[node \n] (N\lay-\i) at (\x,\y) {$\Label[\lay]$};

			\ifnum\lay>1
				\foreach \j in {1,...,\Shape[\prev]}{
				\draw[connect,white,line width=1.2] (N\prev-\j) -- (N\lay-\i);
				\draw[connect] (N\prev-\j) -- (N\lay-\i);
				}
			\fi
			}
			\path (N\lay-\N) --++ (0,1+\yshift) node[midway,scale=1.5] {$\vdots$};
		}
	\end{tikzpicture}
	\qquad
	\begin{tikzpicture}[x=2cm,y=1cm]
		\readlist\Shape{4,7,2}
		\readlist\Type{1,2,3}
		\readlist\Label{x,h^{(\prev)},y}

		\def\yshift{0.45}

		\foreachitem \N \in \Shape{
			\def\lay{\Ncnt}
			\pgfmathsetmacro\prev{int(\Ncnt-1)}

			\foreach \i [evaluate={
				\c=int(\i==\N);
				\y=\N/2-\i-\c*\yshift;
				\x=\lay; \n=\Type[\lay];
				}] in {1,...,\N}{

			\node[node \n] (N\lay-\i) at (\x,\y) {$\Label[\lay]$};

			\ifnum\lay>1
				\foreach \j in {1,...,\Shape[\prev]}{
				\draw[connect,white,line width=1.2] (N\prev-\j) -- (N\lay-\i);
				\draw[connect] (N\prev-\j) -- (N\lay-\i);
				}
			\fi
			}

			\path (N\lay-\N) --++ (0,1+\yshift) node[midway,scale=1.5] {$\vdots$};
		}
	\end{tikzpicture}
\end{center}

\subsection[HDR-NN Training]{The Learning Algorithm}

The HDR-NN benchmark applications all share the same standard training algorithm listed below (\ref{alg:cap}). Describing this algorithm in general purpose neural network frameworks is straight forward and plenty of general implementations of the algorithm exists, making the development process easier to target multiple programming paradigms. The configurable parameters of the learning algorithm through out the implementations are the learning rate, the total number of epochs for training, and the batch size for gradient descent iterations.

\begin{algorithm}[h]
	\caption{Mini Batch Gradient Descent with learning rate $\gamma$ and the Mean Squared Error (\texttt{MSE}) cost function}
	\label{alg:cap}
	\begin{algorithmic}
	\Require initial weights $w^{(0)}$, number of epochs $E$, batch size $B$, training data with $T$ entries
	\Ensure final weights $w^{(E*T)}$
	\For{$e = 0 \rightarrow E - 1$}
		\For{$b = 0 \rightarrow T / B$}
			\For{$t = b * B \rightarrow (b+1) * B$}
			\State estimate $\nabla \mathcal{L}(w^{(t)})$ \Comment{$\mathcal{L}$ here is \texttt{MSE}}
			\State compute $\Delta w^{(b)} += - \nabla \mathcal{L}(w^{(t)})$\label{lin:deep-learning-delta-w}
			\EndFor
			\State $w^{(e + 1)} := w^{(e)} + \gamma \Delta w^{(e)}$
		\EndFor
	\EndFor
	\State return $w^{(T)}$
	\end{algorithmic}
\end{algorithm}

% \subsection{Training Configurations}

% The model structure can be configured in the same manner across the implementations, as well as the learning algorithm configuration. This means that the shape of the model, the input parameters, the connections between the neuron can be configured in the same manner across the implementations. Furthermore, the learning rate, the number of epochs, and the batch size are also configurable in the same manner. Once the different implementations are configured in a similar manner, the training of the model is completed and the network accuracies are compared.

% ============================================
%        Development
% ============================================

\chapter{Development}

The HDR-NN benchmark applications were completed in different programming languages and in PyTorch. Details about the target environment and the benchmark implementations are layed out in this chapter

\section[iMX6 Custom Board Target]{Targeting iMX6SDB}

The target environment necessitates the use of cross compilers and as part of the development process multiple build environments and systems were examined. Ultimately, the primary platform that ended up being used was the Yocto Project extensible SDK (eSDK) based application development process running on a standard linux based build environment. The QEMU emulator was also employed at various staged to check the build, and further test the application before moving onto tests on the actual hardware.

\subsection{Compiler Toolchains \& Yocto Recipes}

The \textit{meta-freescale} Yocto BSP layer by NXP supports the target processor and in combination with the Poky reference distribution provides an eSDK that was primarily used to test and develop the benchmark applications.

GCC based cross compilers and debuggers were usefull for the \texttt{C}, \texttt{C++}  programs. The \textit{meta-python} layer provided by Open Embedded was also useful in allowing for applications using Python and Numpy. The general portability of the benchmark applications and the Yocto project allows for further experiments to be conducted on different target architectures as well.

\subsection{Building PyTorch for iMX6SDB}

PyTorch project provides LibTorch as a binary distribution of all the headers, libraries, CMake configurations required to use PyTorch. However the PyTorch project does not provide these binaries for iMX6SDB. The source code could however, with some effort, be used to generate these binaries and for this project a QEMU based user-mode emulation was used for native compilation of the libtorch binaries.

\subsection[ECU / iMX6 Evaluation Board Overview]{i.MX6 Overview}

The iMX6 series is designed for high performance low power applications and target boards are configured with a single Cortex A9 core with the ARMv7 ISA. The processor supports NEON single-instruction multiple-data (SIMD) instructions, allowing for SIMD vector operations within the training program

\section{HDR-NN Implementation}

With the primary focus on training, MNIST dataset was primarily loaded in an easily readable format appropriate to the corresponding paradigms and the correctness verification routines and execution statistics measurement runs were seperated. The benchmark executions did not produce disk I/O after the dataset was read, unlike the correctness verification runs which produced the final weights from the execution runs that were subsequently compared with the other benchmark program execution output weights

\subsection{The Reference HDR-NN in Python}

This is the baseline implementation and follows close to the implementation exhibitied on \href{http://neuralnetworksanddeeplearning.com}{neuralnetworksanddeeplearning.com}. The implementation uses the n-dimensional array data structure present in the popular Python programming language library Numpy. The following listing shows the function that performs feedforward pass in the Network.

\begin{lstlisting}[language=Python]
	class Network(object):

	def __init__(self, sizes):
		"""Initialise neural network"""
		self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
		self.weights = [np.random.randn(y, x)
		for x, y in zip(sizes[:-1], sizes[1:])]

	def feedforward(self, a):
		for b, w in zip(self.biases, self.weights):
			a = sigmoid(np.dot(w, a)+b)
		return a
\end{lstlisting}

% \subsection[Tensorflow Lite]{Tensorflow Lite based HDR-NN}

% Developing ANNs on tensorflow using Keras is straightforward with good support and well documented APIs. Building the same model for a Tensorflow Lite (TFLite) was more involved however still straightforward

\subsection{PyTorch based HDR-NN}

Developing ANNs using PyTorch is straightforward with good support and well documented APIs. There were two primary choices for programming language to write the neural network in PyTorch, namely Python and C++. PyTorch project does not provide binaries for either language choice for iMX6SDB however with the source code of the project being available, the libtorch binaries were generated as mention in the previous section.

The implementation used the MNIST made available by Torchvision library which is mainted under the PyTorch project and configured a Module to implement the same learning algorithm as that outlined in the Numpy based Python implementation.

\begin{lstlisting}[language=C++]
struct Net : torch::nn::Module {
	Net() {
		// Construct and register two Linear submodules.
		fc1 = register_module("fc1", torch::nn::Linear(784, 30));
		fc2 = register_module("fc2", torch::nn::Linear(30, 10));
	}

	// Implement the Net's algorithm.
	torch::Tensor forward(torch::Tensor x) {
		// Use one of many tensor manipulation functions.
		x = torch::sigmoid(fc1->forward(x.reshape({x.size(0), 784})));
		x = torch::sigmoid(fc2->forward(x));
		return x;
	}

	// Use one of many "standard library" modules.
	torch::nn::Linear fc1{nullptr}, fc2{nullptr};
};
\end{lstlisting}


\subsection{C based HDR-NN}

The \texttt{C} implementation had the least amount of external dependencies and contained the data structures of the neural network in float arrays within structs shown in the listing below. The learning algorithm was implemented to remain identical with those used in the other implementations.

\begin{lstlisting}[language=C]
/* HDR Neural Network */
typedef struct
{
	float bias;
	float *weights;
	float *nabla_w;
} Neuron;

typedef struct LayerT
{
	int size;
	int incidents;
	Neuron *neurons;
	float *activations;
	float *z_values;
	float *nabla_b;
	struct LayerT *next;
	struct LayerT *previous;
} Layer; // Network layers except for input

typedef struct
{
	Layer *layers;
	int depth;
} Network; // HDRNN
\end{lstlisting}

\subsection{CPP based HDR-NN}

The CPP implementation used the n-dimensional array data structure feature of Eigen. It shares the same structure as the Numpy based Python implementation with the same learning algorithm show below.

\begin{lstlisting}[language=C++]
void mini_batch_sgd()
{
	// Initialize Nabla matrixes
	std::vector<nabla> nablas;
	for (std::size_t i = 0; i < network.size(); i++)
		nablas.push_back(
					nabla(network[i].weights.rows(),
						network[i].weights.cols())
					);

	// Go through the training data by batches
	for (std::size_t i = 0; i < mnist_loader::train.size()
				; i += BATCH_SIZE)
	{
		// Perform Backpropagation on the batch
		for (std::size_t j = 0; j < BATCH_SIZE; j++)
			back_propogate(nablas,
						mnist_loader::train[i+j].data,
						mnist_loader::train[i+j].label);

		// Update the weights and biases of the network
		for (std::size_t j = 0; j < network.size(); j++)
			network[j].update(nablas[j]);

		// Zero out the nabla matrixes
		for (std::size_t j = 0; j < nablas.size(); j++)
			nablas[j].zero_out();
	}
}
\end{lstlisting}